# streamlit run main.py
import asyncio  # éåŒæœŸå‡¦ç†ã‚’è¡Œã†ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import base64
from dotenv import load_dotenv
import edge_tts
import json
import langchain
from langchain.agents import initialize_agent, AgentType, Tool
from langchain.callbacks import StreamlitCallbackHandler
from langchain.prompts import MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.schema import SystemMessage
from langchain_openai import ChatOpenAI
from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser
import pandas as pd
import params as prm
from PIL import Image
import streamlit as st
# from tools import build_db_for_rag # å¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ã™ã‚‹
from tools import get_response_by_rag, get_groundplan_function
from tools import UpdateBuildingParameterTool
from tools import remove_building_parameters, load_default_parameters, export_3D_building_model, remove_object
# from tools import load_saved_parameters
from tools import recognize_speech

# Set config
load_dotenv('.env', verbose=True)
langchain.debug = True

def init_page():
    st.set_page_config(
        page_title="äº¬éƒ½å¸‚ æ™¯è¦³æ¤œè¨ãƒ„ãƒ¼ãƒ«ï¼ˆãƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—ç‰ˆï¼‰",
        page_icon="ğŸ¤–"
    )
    st.header("äº¬éƒ½å¸‚ æ™¯è¦³æ¤œè¨ãƒ„ãƒ¼ãƒ«ï¼ˆãƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—ç‰ˆï¼‰")
    # st.sidebar.title("Options")

def autoplay_audio(file_path: str):
    with open(file_path, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        md = f"""
            <audio controls autoplay="true">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """
        st.markdown(
            md,
            unsafe_allow_html=True,
        )

def get_agent(memory=None):

    with open(prm.path_default_file) as f:
        dict = json.load(f)
    lst_tmp = [k[:-2] for k in dict.keys() if k.endswith('_r') or k.endswith('_g') or k.endswith('_b')] \
         + [k for k in dict.keys() if not (k.endswith('_r') or k.endswith('_g') or k.endswith('_b'))]
    
    
    llm = ChatOpenAI(model_name=prm.model_name_gpt35, streaming=True, temperature=0)

    agent_kwargs = {
        "system_message": SystemMessage(
            content='ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒå»ºç‰©ã®ãƒ‡ã‚¶ã‚¤ãƒ³ä½œæˆã‚’æ”¯æ´ã™ã‚‹ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\
                ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ã®å…¥åŠ›ã«å¿œã˜ã¦å»ºç‰©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ•´ç†ã—ã¾ã™ã€‚ \
                å†…å®¹ãŒä¸æ˜ãªé …ç›®ãŒã‚ã‚‹å ´åˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å•ã„åˆã‚ã›ã¦ãã ã•ã„ã€‚ \
                ãªãŠã€ã‚ãªãŸã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ ' \
                # + 'ãƒ»`build_db_for_rag`ï¼š äº¬éƒ½å¸‚ã®å»ºç‰©ã«é–¢ã™ã‚‹æ³•è¦ã‚’DBã«ç™»éŒ²ã—ã€æ¤œç´¢ã—ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`get_response_by_rag`ï¼š äº¬éƒ½å¸‚ã®å»ºç‰©ã«é–¢ã™ã‚‹æ³•è¦ã‚’æ¤œç´¢ã—ã€å»ºç¯‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚ ' \
                # + 'ãƒ»`get_groundplan_function`ï¼š å¹³é¢å›³ã‚’èª­ã¿è¾¼ã‚“ã§å»ºç‰©ã®å¹³é¢ã®å½¢çŠ¶ã‚’å–å¾—ã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`update_building_parameters`ï¼š ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`remove_building_parameters`ï¼š ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å»ã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`load_default_parameters`ï¼š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚ ' \
                # + 'ãƒ»`load_saved_parameters`ï¼š æœ€å¾Œã«ä½¿ç”¨ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`export_3D_building_model`ï¼š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€å»ºç‰©ã®3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ ' \
                + 'ãƒ»`remove_object`ï¼š 3Dãƒ¢ãƒ‡ãƒ«ã‚’é™¤å»ã—ã¾ã™ã€‚ ' \
                + ''
        ),
        "extra_prompt_messages": [MessagesPlaceholder(variable_name="memory")],
    }

    agent = initialize_agent(
        tools=[             
                # Tool(
                #     name = 'build_db_for_rag',
                #     func = build_db_for_rag,
                #     description = 'äº¬éƒ½å¸‚ã®å»ºç‰©ã«é–¢ã™ã‚‹æ³•è¦ã‚’DBã«ç™»éŒ²ã—ã€æ¤œç´¢ã—ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚',
                # ),
                Tool(
                    name = 'get_response_by_rag',
                    func = get_response_by_rag,
                    description = 'ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å•ã„ã«å¿œã˜ã¦äº¬éƒ½å¸‚ã®å»ºç‰©ã«é–¢ã™ã‚‹æ³•è¦ã‚’æ¤œç´¢ã—ã€å»ºç¯‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚',
                ),
                # Tool(
                #     name = 'get_groundplan_function',
                #     func = get_groundplan_function,
                #     description = "å¹³é¢å›³ã‚’èª­ã¿ã“ã‚“ã§ã€ãã®é ‚ç‚¹åº§æ¨™ã‚’å–å¾—ã™ã‚‹",
                # ),
                UpdateBuildingParameterTool(), 
                Tool(
                    name = 'remove_building_parameters',
                    func = remove_building_parameters,
                    description = 'Use this tool to remove a building parameter.' \
                        + ' Available arguments are one in the following list ' \
                        + str(list(set(lst_tmp))),
                ),
                Tool(
                    name = 'load_default_parameters',
                    func = load_default_parameters,
                    description = 'Use this tool to load the default parameters.',
                ),
                # Tool(
                #     name = 'load_saved_parameters',
                #     func = load_saved_parameters,
                #     description = 'Use this tool to load the last saved parameters.',
                # ),
                Tool(
                    name = 'export_3D_building_model',
                    func = export_3D_building_model,
                    description = 'Use this tool to export a 3D model of the building.',
                ),
                Tool(
                    name = 'remove_object',
                    func = remove_object,
                    description = 'Use this tool to remove a 3D model from the screen.',
                ),
               ],
        llm=llm,
        agent=AgentType.OPENAI_FUNCTIONS,
        agent_kwargs=agent_kwargs,
        memory=memory,
        verbose=True,
    )
    return agent

def get_memory():
    # get memory from session state if it exists
    memory = st.session_state.get("memory", None)
    # initialize memory if it doesn't exist
    if memory is None:
        memory = ConversationBufferMemory(memory_key="memory", return_messages=True)
    return memory

def update_dataframe(df):
    bcg_rgb, bcw_rgb = [0, 0, 0], [0, 0, 0]
    with open(prm.path_tmp_file) as f:
        dict = json.load(f)
    for k, v in dict.items():
        if k == 'base_shape':
            pass
        elif k == 'base_color_ground_r':
            bcg_rgb[0] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcg_rgb)
            df.loc['base_color_ground'] = ['base_color_ground', prm.dict_synonym['base_color_ground'], hex_code]
        elif k == 'base_color_ground_g':
            bcg_rgb[1] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcg_rgb)
            df.loc['base_color_ground'] = ['base_color_ground', prm.dict_synonym['base_color_ground'], hex_code]
        elif k == 'base_color_ground_b':
            bcg_rgb[2] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcg_rgb)
            df.loc['base_color_ground'] = ['base_color_ground', prm.dict_synonym['base_color_ground'], hex_code]
        elif k == 'base_color_wall_r':
            bcw_rgb[0] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcw_rgb)
            df.loc['base_color_wall'] = ['base_color_wall', prm.dict_synonym['base_color_wall'], hex_code]
        elif k == 'base_color_wall_g':
            bcw_rgb[1] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcw_rgb)
            df.loc['base_color_wall'] = ['base_color_wall', prm.dict_synonym['base_color_wall'], hex_code]
        elif k == 'base_color_wall_b':
            bcw_rgb[2] = v
            hex_code = "#{:02x}{:02x}{:02x}".format(*bcw_rgb)
            df.loc['base_color_wall'] = ['base_color_wall', prm.dict_synonym['base_color_wall'], hex_code]
        elif k == 'base_shape':
            pass
        elif k == 'vertex_coordinates':
            df.loc[k] = [k, prm.dict_synonym[k], 'èª­è¾¼æ¸ˆ']
        elif k in prm.dict_synonym:
            df.loc[k] = [k, prm.dict_synonym[k], str(v)]
        else :
            df.loc[k] = [k, k, str(v)]
    # è¡¨ç¤º
    return df[["df_synonym", "df_value"]].style.map(lambda x: 'background-color: ' + x if (type(x) is str and x.startswith('#')) else '')

if __name__ == "__main__":
    init_page()
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’ä½œæˆ
    prompt_text = st.chat_input()

    # è¨­å®šå€¤ã‚’è¡¨ç¤ºã™ã‚‹
    st.sidebar.markdown("## ç¾åœ¨ã®ãƒ‡ã‚¶ã‚¤ãƒ³æ¡ä»¶")
    df = pd.DataFrame({'df_key': [], 'df_synonym': [], 'df_value': []})
    styler = update_dataframe(df)
    placeholder = st.sidebar.dataframe(
        styler,
        column_config = {"df_synonym": "é …ç›®", "df_value": "è¨­å®šå€¤"},
        hide_index=True,
        )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    #  ref: https://discuss.streamlit.io/t/are-there-any-ways-to-clear-file-uploader-values-without-using-streamlit-form/40903
    if "file_uploader_key" not in st.session_state:
        st.session_state["file_uploader_key"] = 0
    if "uploaded_files" not in st.session_state:
        st.session_state["uploaded_files"] = []

    st.sidebar.markdown("### ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    with open(prm.path_args) as f:
        dict_args = json.load(f)
    file = st.sidebar.file_uploader('å¹³é¢å›³ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„.', 
                                    type=['jpg', 'jpeg', 'png'], 
                                    accept_multiple_files=False,
                                    key=st.session_state["file_uploader_key"],
                                    )
    if file:
        st.session_state["uploaded_files"] = file
        # st.sidebar.markdown(f'{file.name} ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ.')
        dict_args['image_path'] = file.name
        # ç”»åƒã‚’ä¿å­˜ã™ã‚‹
        with open(prm.path_args, 'w') as f:
            json.dump(dict_args, f, indent=4)
        # åº•é¢å›³èª­ã¿è¾¼ã¿æ©Ÿèƒ½ã‚’å®Ÿè¡Œã™ã‚‹
        str_out  = get_groundplan_function()
        # # ä¿å­˜ã—ãŸç”»åƒã‚’è¡¨ç¤º
        # st.sidebar.image(Image.open(prm.path_image_dir + dict_args['image_path']), width=400)
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.messages.append({"role": "assistant", "content": str_out})
        st.chat_message("user").write(str_out)
        st.session_state["file_uploader_key"] += 1
        st.rerun()

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.sidebar.markdown("## ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    # éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    if st.sidebar.button('ğŸ¤ éŸ³å£°å…¥åŠ›'):
        prompt_voice = recognize_speech()  # éŸ³å£°èªè­˜é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’å–å¾—
    else:
        prompt_voice = ''
    #     # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ä»¥å‰ã®èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    #     prompt = st.session_state.get('recognized_text', "")
    
    on_voice = st.sidebar.toggle("ğŸ“¢ éŸ³å£°å‡ºåŠ›")
    # on_debug = st.sidebar.toggle("ğŸ’» é–‹ç™ºè€…ç”¨")

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": 'ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯å»ºç‰©ç”Ÿæˆãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã™ã€‚  \n ' \
                + 'ç§ã¯ã‚ãªãŸãŒå»ºç‰©ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’è¡Œã†ãŸã‚ã«ã€æ¬¡ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚  \n  \n ' \

                + '  \n **:orange[ï¼œè¨­è¨ˆã®å‰æã«é–¢ã‚ã‚‹æ©Ÿèƒ½ï¼]**  \n ' \
                + ':orange[ â€• äº¬éƒ½å¸‚ã®å»ºç‰©ã«é–¢ã™ã‚‹æ³•è¦ã‚’æ¤œç´¢ã—ã€ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã„ã¾ã™ã€‚]  \n ' \

                + '  \n **:orange[ï¼œãƒ‡ã‚¶ã‚¤ãƒ³ã®ä½œæˆ/å¤‰æ›´ã«é–¢ã‚ã‚‹æ©Ÿèƒ½ï¼]**  \n ' \
                + ':orange[ â€• ãƒ‡ã‚¶ã‚¤ãƒ³ã®ã²ãªå‹ã‚’å–å¾—ã—ã¾ã™ã€‚  \n ' \
                + ' â”” æ¨™æº–ã§ã¯æœ€å¾Œã«ä½¿ç”¨ã—ãŸãƒ‡ã‚¶ã‚¤ãƒ³æ¡ä»¶ãŒå¾©å…ƒã•ã‚Œã¾ã™ãŒã€ã¯ã˜ã‚ã‹ã‚‰ä½œæˆã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚]  \n '
                + ':orange[ â€• å»ºç¯‰ã®å¹³é¢å›³ã‚’èª­ã¿è¾¼ã‚“ã§ã€å»ºç‰©ã®å½¢çŠ¶ã‚’å–å¾—ã—ã¾ã™ã€‚  \n ' \
                + ' â”” ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚]  \n ' \
                + ':orange[ â€• å»ºç¯‰ç‰©ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å¤‰æ›´ã—ã¾ã™ã€‚  \n ' \
                + ' â”” ç¾åœ¨ã¯ã€å»ºç‰©ã®éšæ•°ãƒ»å¹…ãƒ»å¥¥è¡Œãƒ»å£ã®è‰²ã‚’æŒ‡å®šå¯èƒ½ã§ã™ã€‚ï¼ˆ1åº¦ã«è¤‡æ•°ã‚’æŒ‡å®šå¯èƒ½ï¼‰  \n ' \
                + ' â”” ä¸è¦ãªãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ï¼ˆ1åº¦ã«1ã¤ã¾ã§æŒ‡å®šå¯èƒ½ï¼‰]  \n ' \

                + '  \n **:orange[ï¼œ3Dãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¤ºã«é–¢ã‚ã‚‹æ©Ÿèƒ½ï¼]**  \n ' \
                + ':orange[ â€• ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€å»ºç‰©ã®3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚]  \n ' \
                + ':orange[ â€• ç”»é¢ã‹ã‚‰3Dãƒ¢ãƒ‡ãƒ«ã‚’é™¤å»ã—ã¾ã™ã€‚]  \n ' \

                + '  \n å‰å›ã®æœ€å¾Œã®ãƒ‡ã‚¶ã‚¤ãƒ³æ¡ä»¶ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚  \n ãã‚Œã§ã¯ãƒ‡ã‚¶ã‚¤ãƒ³ã®ä½œæˆã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚'
            }
        ]
        
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt_text is not None or len(prompt_voice)>0: # å…¥åŠ›ãŒç©ºã§ã¯ãªã„å ´åˆ 
        prompt = ''
        if prompt_text is not None:
            prompt += prompt_text
        if len(prompt_voice):
            prompt += prompt_voice
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        memory = get_memory()
        agent = get_agent(memory=memory)

        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(st.empty())
            response = agent.run(prompt, callbacks=[st_cb])
            # response = st.session_state.agent.run(prompt, callbacks=[st_cb])

            # save agent memory to session state
            st.session_state.memory = agent.memory
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.write(response)
            
            # éŸ³å£°ã‚’å‡ºåŠ›ã™ã‚‹
            if on_voice:
                # éŸ³å£°åˆæˆã®è¨­å®šã‚’è¡Œã„ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                communicate = edge_tts.Communicate(response, 'ja-JP-NanamiNeural', rate='+0%', pitch='+0Hz')
                asyncio.run(communicate.save(prm.path_audio))
                # ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã‚’ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªä¸Šã§å†ç”Ÿ
                # st.audio(prm.path_audio)
                autoplay_audio(prm.path_audio)
        
        st.rerun()
        # placeholder.dataframe(
        #     update_dataframe(pd.DataFrame({'df_key': [], 'df_synonym': [], 'df_value': []})),
        #     column_config = {"df_synonym": "é …ç›®", "df_value": "è¨­å®šå€¤"},
        #     hide_index=True,
        #     )


